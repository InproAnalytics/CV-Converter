import os
import re
import json
import time
import logging

from pdf_processor import prepare_cv_text
from chatgpt_client import ask_chatgpt
from postprocess import (
    postprocess_filled_cv,
    clean_text_fields,
    validate_cv_schema,
)
from utils import save_json

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
INPUT_PDF = "data_input/CV Manuel Wolfsgruber.pdf"
OUTPUT_JSON = "data_output/result_Manuel.json"


# ============================================================
# üîπ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ============================================================
def filter_explicit_domains(text: str, domains: list[str]) -> list[str]:
    """–†–∞—Å—à–∏—Ä—è–µ—Ç –ø–æ–∏—Å–∫ –¥–æ–º–µ–Ω–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É."""
    domain_keywords = {
        "Machine Learning": ["machine learning", "ml", "deep learning", "neural network"],
        "AI": ["artificial intelligence", "ai model", "generative ai"],
        "Data Engineering": ["data pipeline", "data ingestion", "etl", "databricks", "snowflake"],
        "MLOps": ["mlops", "model deployment", "ci/cd for models", "vertex ai", "sagemaker"],
        "Cloud": ["aws", "azure", "gcp", "kubernetes", "terraform"],
        "Analytics": ["bi", "power bi", "analytics", "dashboards", "reporting"],
        "IoT": ["iot", "connected devices", "sensor data", "predictive maintenance"],
        "Finance": ["banking", "fintech", "risk model", "insurance"],
        "Healthcare": ["medical", "health", "pharma", "clinical"],
        "Manufacturing": ["factory", "industrial", "process optimization", "production"],
    }

    found = set()
    text_l = text.lower()
    for domain, keywords in domain_keywords.items():
        if any(k in text_l for k in keywords):
            found.add(domain)

    if domains:
        found.update(domains)

    return sorted(found)


def shorten_profile_summary(text: str, max_chars: int = 1200) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è."""
    if not text:
        return ""
    text = re.sub(r'\s+', ' ', text.strip())
    if len(text) > max_chars:
        cut = text[:max_chars]
        if "." in cut:
            cut = cut[:cut.rfind(".") + 1]
        return cut.strip()
    return text.strip()


# ============================================================
# üîπ –ì–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
# ============================================================

def main():
    start_time = time.time()
    logging.basicConfig(level=logging.INFO)
    logging.info("üöÄ Starting CV Extraction Pipeline...")

    # 1Ô∏è‚É£ –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF ‚Üí –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
    prepared_text, raw_text = prepare_cv_text(INPUT_PDF)

    # 2Ô∏è‚É£ –í—ã–∑–æ–≤ GPT
    logging.info("üì® Sending text to GPT (mode='details')...")
    result = ask_chatgpt(prepared_text, mode="details")

    # 3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Ä–∞–∑–±–æ—Ä –æ—Ç–≤–µ—Ç–∞
    if "raw_response" in result:
        try:
            filled_json = json.loads(result["raw_response"])

            # 4Ô∏è‚É£ –û—Å–Ω–æ–≤–Ω–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            logging.info("üß© Running structured postprocessing...")
            filled_json = postprocess_filled_cv(filled_json, raw_text)

            # 5Ô∏è‚É£ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞
            logging.info("üßº Cleaning and validating result...")
            filled_json = clean_text_fields(filled_json)

            missing_fields = validate_cv_schema(filled_json)
            if missing_fields:
                logging.warning(f"‚ö†Ô∏è Missing fields: {missing_fields}")

            # 6Ô∏è‚É£ –î–æ–º–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ summary
            filled_json["domains"] = filter_explicit_domains(
                prepared_text, filled_json.get("domains", [])
            )
            filled_json["profile_summary"] = shorten_profile_summary(
                filled_json.get("profile_summary", "")
            )

            # 7Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            filled_json["_meta"] = {
                "source_pdf": INPUT_PDF,
                "generated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                "processing_time_sec": round(time.time() - start_time, 2),
            }

            # 8Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            save_json(OUTPUT_JSON, filled_json)
            logging.info(f"‚úÖ Result saved to: {OUTPUT_JSON}")

        except json.JSONDecodeError as e:
            logging.error("‚ùå JSON parsing error:")
            logging.error(e)
            logging.warning("‚ö†Ô∏è GPT raw response:")
            print(result["raw_response"])

    else:
        logging.error("‚ùå GPT did not return a valid response.")

    elapsed = time.time() - start_time
    logging.info(f"‚úÖ Pipeline completed in {elapsed:.2f} seconds")


# ============================================================
# üîπ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
# ============================================================

if __name__ == "__main__":
    main()
